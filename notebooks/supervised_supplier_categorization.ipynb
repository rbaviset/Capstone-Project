{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282fc228-3fca-44c9-a054-9292819e551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (30, 39)\n",
      "   supplier  fiscal_year      revenue         COGS  gross_margin_pct  \\\n",
      "0    Micron         2015   16300000.0   11660000.0              28.5   \n",
      "1   Samsung         2015  176500000.0  108892000.0              37.5   \n",
      "2  SK Hynix         2015   16900000.0   12168000.0              28.0   \n",
      "3    Micron         2016   12400000.0   10210000.0              17.6   \n",
      "4   Samsung         2016  177000000.0  109740000.0              38.0   \n",
      "\n",
      "      cash_flow  debt_equity_ratio  cost_savings     PPV    QP  ...  \\\n",
      "0  7.800000e+06               0.62          10.0 -1000.0  85.0  ...   \n",
      "1  3.900000e+10               0.17          10.0  -500.0  95.0  ...   \n",
      "2  8.000000e+06               0.70           8.0 -1500.0  85.0  ...   \n",
      "3  3.100000e+06               0.70           5.0 -1000.0  85.0  ...   \n",
      "4  4.550000e+10               0.15           7.0  -500.0  95.0  ...   \n",
      "\n",
      "   score_lead_time_attainment  score_carbon  score_renewable_energy_usage  \\\n",
      "0                    0.909091      0.518519                      0.088235   \n",
      "1                    1.000000      0.000000                      0.029412   \n",
      "2                    0.909091      0.074074                      0.000000   \n",
      "3                    0.909091      0.562963                      0.147059   \n",
      "4                    1.000000      0.111111                      0.058824   \n",
      "\n",
      "   score_plastic_recycle  score_human_rights_compliance_score  \\\n",
      "0               0.153846                             0.142857   \n",
      "1               0.000000                             0.000000   \n",
      "2               0.076923                             0.142857   \n",
      "3               0.307692                             0.285714   \n",
      "4               0.153846                             0.000000   \n",
      "\n",
      "   score_cost_block  score_qd_block  score_esg_block  composite_score  \\\n",
      "0          0.545455         0.30303         0.225864         0.468041   \n",
      "1          0.500000         1.00000         0.007353         0.850735   \n",
      "2          0.513986         0.30303         0.073464         0.449654   \n",
      "3          0.353147         0.30303         0.325857         0.458809   \n",
      "4          0.384615         1.00000         0.080945         0.846556   \n",
      "\n",
      "   allocation_percent  \n",
      "0                25.0  \n",
      "1                50.0  \n",
      "2                25.0  \n",
      "3                25.0  \n",
      "4                50.0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "\n",
      "Model Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Developing       1.00      1.00      1.00         2\n",
      "     Limited       1.00      1.00      1.00         2\n",
      "   Preferred       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [0 2 0]\n",
      " [0 0 2]]\n",
      "\n",
      "Saved:\n",
      " - model1_xgb.json\n",
      " - model1_scaler.pkl\n",
      " - model1_psl_encoder.pkl\n",
      " - supplier_categorization_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Model-1B: Supervised Supplier Categorization (XGBoost Classifier)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Load input feature table (with PSL target from Model-1A)\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(\"../data_processed/historical_features_with_allocation.csv\")\n",
    "\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Prepare Target (PSL_status) \n",
    "# -------------------------------------------------------------\n",
    "# Using PSL_status from Model-1A\n",
    "psl_encoder = LabelEncoder()\n",
    "df[\"PSL_code\"] = psl_encoder.fit_transform(df[\"PSL_status\"])\n",
    "\n",
    "# Save the encoder\n",
    "joblib.dump(psl_encoder, \"../models/model1_psl_encoder.pkl\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Prepare Features for Model-1B (same as your old logic)\n",
    "# -------------------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"fiscal_year\",\n",
    "    \"supplier_code\",\n",
    "    \"gross_margin_pct\",\n",
    "    \"cash_flow\",\n",
    "    \"debt_equity_ratio\",\n",
    "    \"node_parity\",\n",
    "    \"DDR_gen_support\",\n",
    "    \"geo_risk\",\n",
    "    \"tariff_risk\",\n",
    "    \"chip_shortage_impact\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"PSL_code\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Scaling (same as old tested approach)\n",
    "# -------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "joblib.dump(scaler, \"../models/model1_scaler.pkl\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Train-Test Split\n",
    "# -------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Train XGBoost Classifier\n",
    "# -------------------------------------------------------------\n",
    "model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"multi:softprob\",\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7. Evaluate\n",
    "# -------------------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nModel Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(psl_encoder.inverse_transform(y_test),\n",
    "                            psl_encoder.inverse_transform(y_pred)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8. Save Model + Predictions\n",
    "# -------------------------------------------------------------\n",
    "model.save_model(\"../models/model1_xgb.json\")\n",
    "\n",
    "df[\"PSL_predicted\"] = psl_encoder.inverse_transform(model.predict(X_scaled))\n",
    "\n",
    "df.to_csv(\"../data_processed/supplier_categorization_predictions.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - model1_xgb.json\")\n",
    "print(\" - model1_scaler.pkl\")\n",
    "print(\" - model1_psl_encoder.pkl\")\n",
    "print(\" - supplier_categorization_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f5e43-fc9a-4ad1-b7cf-3ac46bf4f00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
