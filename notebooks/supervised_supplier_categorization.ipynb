{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282fc228-3fca-44c9-a054-9292819e551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (30, 39)\n",
      "   supplier  fiscal_year      revenue         COGS  gross_margin_pct  \\\n",
      "0    Micron         2015   16300000.0   11660000.0              28.5   \n",
      "1   Samsung         2015  176500000.0  108892000.0              37.5   \n",
      "2  SK Hynix         2015   16900000.0   12168000.0              28.0   \n",
      "3    Micron         2016   12400000.0   10210000.0              17.6   \n",
      "4   Samsung         2016  177000000.0  109740000.0              38.0   \n",
      "\n",
      "      cash_flow  debt_equity_ratio  cost_savings     PPV    QP  ...  \\\n",
      "0  7.800000e+06               0.62          10.0 -1000.0  85.0  ...   \n",
      "1  3.900000e+10               0.17          10.0  -500.0  95.0  ...   \n",
      "2  8.000000e+06               0.70           8.0 -1500.0  85.0  ...   \n",
      "3  3.100000e+06               0.70           5.0 -1000.0  85.0  ...   \n",
      "4  4.550000e+10               0.15           7.0  -500.0  95.0  ...   \n",
      "\n",
      "   score_lead_time_attainment  score_carbon  score_renewable_energy_usage  \\\n",
      "0                    0.909091      0.518519                      0.088235   \n",
      "1                    1.000000      0.000000                      0.029412   \n",
      "2                    0.909091      0.074074                      0.000000   \n",
      "3                    0.909091      0.562963                      0.147059   \n",
      "4                    1.000000      0.111111                      0.058824   \n",
      "\n",
      "   score_plastic_recycle  score_human_rights_compliance_score  \\\n",
      "0               0.153846                             0.142857   \n",
      "1               0.000000                             0.000000   \n",
      "2               0.076923                             0.142857   \n",
      "3               0.307692                             0.285714   \n",
      "4               0.153846                             0.000000   \n",
      "\n",
      "   score_cost_block  score_qd_block  score_esg_block  composite_score  \\\n",
      "0          0.545455         0.30303         0.225864         0.468041   \n",
      "1          0.500000         1.00000         0.007353         0.850735   \n",
      "2          0.513986         0.30303         0.073464         0.449654   \n",
      "3          0.353147         0.30303         0.325857         0.458809   \n",
      "4          0.384615         1.00000         0.080945         0.846556   \n",
      "\n",
      "   allocation_percent  \n",
      "0                25.0  \n",
      "1                50.0  \n",
      "2                25.0  \n",
      "3                25.0  \n",
      "4                50.0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "\n",
      "Best params: {'xgb__colsample_bytree': 0.7, 'xgb__learning_rate': 0.03, 'xgb__max_depth': 3, 'xgb__n_estimators': 200, 'xgb__reg_lambda': 0.5, 'xgb__subsample': 0.8}\n",
      "Best CV accuracy: 1.0\n",
      "\n",
      "Model-1B: Supplier Categorization — Evaluation (Leakage-safe)\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Developing       1.00      1.00      1.00         2\n",
      "     Limited       1.00      1.00      1.00         2\n",
      "   Preferred       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 0 0]\n",
      " [0 2 0]\n",
      " [0 0 2]]\n",
      "\n",
      "Saved:\n",
      " - model1_xgb.json\n",
      " - model1_scaler.pkl\n",
      " - model1_psl_encoder.pkl\n",
      " - supplier_categorization_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Model-1B: Supervised Supplier Categorization \n",
    "# Saves: model1_xgb.json, model1_scaler.pkl, model1_psl_encoder.pkl,\n",
    "#          supplier_categorization_predictions.csv\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------------\n",
    "INPUT_FILE = \"../data_processed/historical_features_with_allocation.csv\"\n",
    "\n",
    "OUT_PRED_FILE = \"../data_processed/supplier_categorization_predictions.csv\"\n",
    "\n",
    "MODEL_JSON_FILE = \"../models/model1_xgb.json\"\n",
    "SCALER_FILE = \"../models/model1_scaler.pkl\"\n",
    "PSL_ENCODER_FILE = \"../models/model1_psl_encoder.pkl\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Load input feature table (with PSL target from Model-1A)\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) Ensure supplier_code exists (if EDA didn't create it)\n",
    "# -------------------------------------------------------------\n",
    "# Best practice: supplier_code should be created in EDA and reused everywhere.\n",
    "# But this fallback keeps the script runnable.\n",
    "if \"supplier_code\" not in df.columns:\n",
    "    if \"supplier\" not in df.columns:\n",
    "        raise ValueError(\"Expected either 'supplier_code' or 'supplier' column in input.\")\n",
    "    supplier_encoder = LabelEncoder()\n",
    "    df[\"supplier_code\"] = supplier_encoder.fit_transform(df[\"supplier\"].astype(str))\n",
    "    joblib.dump(supplier_encoder, \"../models/model1_supplier_encoder.pkl\")\n",
    "    print(\"NOTE: 'supplier_code' not found. Created from 'supplier' and saved model1_supplier_encoder.pkl\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3) Prepare target (PSL_status -> PSL_code)\n",
    "# -------------------------------------------------------------\n",
    "if \"PSL_status\" not in df.columns:\n",
    "    raise ValueError(\"Expected column 'PSL_status' (from Model-1A) in input file.\")\n",
    "\n",
    "psl_encoder = LabelEncoder()\n",
    "df[\"PSL_code\"] = psl_encoder.fit_transform(df[\"PSL_status\"].astype(str))\n",
    "\n",
    "# Save PSL encoder for FY25 predictions\n",
    "joblib.dump(psl_encoder, PSL_ENCODER_FILE)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4) Prepare features (same feature list as your old tested logic)\n",
    "# -------------------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"fiscal_year\",\n",
    "    \"supplier_code\",\n",
    "    \"gross_margin_pct\",\n",
    "    \"cash_flow\",\n",
    "    \"debt_equity_ratio\",\n",
    "    \"node_parity\",\n",
    "    \"DDR_gen_support\",\n",
    "    \"geo_risk\",\n",
    "    \"tariff_risk\",\n",
    "    \"chip_shortage_impact\"\n",
    "]\n",
    "\n",
    "missing = [c for c in feature_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required feature columns: {missing}\")\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"PSL_code\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5) Train/Test split\n",
    "# -------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6) Pipeline + GridSearchCV\n",
    "# -------------------------------------------------------------\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Keep grid modest to avoid long runs; expand if needed\n",
    "param_grid = {\n",
    "    \"xgb__n_estimators\": [200, 300, 500],\n",
    "    \"xgb__learning_rate\": [0.03, 0.05, 0.1],\n",
    "    \"xgb__max_depth\": [3, 5, 7],\n",
    "    \"xgb__subsample\": [0.7, 0.8, 1.0],\n",
    "    \"xgb__colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "    \"xgb__reg_lambda\": [0.5, 1.0, 2.0],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest params:\", grid.best_params_)\n",
    "print(\"Best CV accuracy:\", round(grid.best_score_, 4))\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7) Evaluate on held-out test set\n",
    "# -------------------------------------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nModel-1B: Supplier Categorization — Evaluation (Leakage-safe)\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\n",
    "    classification_report(\n",
    "        psl_encoder.inverse_transform(y_test),\n",
    "        psl_encoder.inverse_transform(y_pred)\n",
    "    )\n",
    ")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8) Save artifacts\n",
    "# -------------------------------------------------------------\n",
    "# Save scaler (fitted on TRAIN ONLY via pipeline)\n",
    "fitted_scaler = best_model.named_steps[\"scaler\"]\n",
    "joblib.dump(fitted_scaler, SCALER_FILE)\n",
    "\n",
    "# Save XGBoost model as JSON (fitted xgb inside pipeline)\n",
    "xgb_fitted = best_model.named_steps[\"xgb\"]\n",
    "xgb_fitted.save_model(MODEL_JSON_FILE)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", os.path.basename(MODEL_JSON_FILE))\n",
    "print(\" -\", os.path.basename(SCALER_FILE))\n",
    "print(\" -\", os.path.basename(PSL_ENCODER_FILE))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9) Predict PSL for full dataset (for step-5 / future chaining)\n",
    "# -------------------------------------------------------------\n",
    "df[\"PSL_predicted\"] = psl_encoder.inverse_transform(best_model.predict(X))\n",
    "\n",
    "df.to_csv(OUT_PRED_FILE, index=False)\n",
    "print(\" -\", os.path.basename(OUT_PRED_FILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f5e43-fc9a-4ad1-b7cf-3ac46bf4f00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
